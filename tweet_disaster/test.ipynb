{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datasets import Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"/data/linqinhong/kaggle/tweet_disaster/train.csv\",dtype={'id': np.int16, 'target': np.int8})\n",
    "test_df=pd.read_csv(\"/data/linqinhong/kaggle/tweet_disaster/test.csv\",dtype={'id': np.int16})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "(3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "train_df.drop_duplicates(\"text\",inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7503, 5)\n",
      "(3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "train_df[\"text\"].fillna(\"\",inplace=True)\n",
    "train_df[\"location\"].fillna(\"\",inplace=True)\n",
    "train_df[\"keyword\"].fillna(\"\",inplace=True)\n",
    "test_df[\"text\"].fillna(\"\",inplace=True)\n",
    "test_df[\"location\"].fillna(\"\",inplace=True)\n",
    "test_df[\"keyword\"].fillna(\"\",inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"keyword\"]+train_df[\"text\"]\n",
    "test_df[\"text\"]=test_df[\"keyword\"]+test_df[\"text\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "from emot import UNICODE_EMOJI\n",
    "def remove_emoji(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        text.replace(emot,\" \".join(UNICODE_EMOJI[emot].replace(\":\",\"\").split()))\n",
    "    return text\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_emoji)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_emoji)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def remove_html(text):\n",
    "    soup=BeautifulSoup(text)\n",
    "    return soup.get_text()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_html)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def remove_mention(text):\n",
    "    pattern=re.compile(r\"@\\w+\")\n",
    "    return re.sub(pattern,\"\",text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_mention)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_mention)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "import contractions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(contractions.fix)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(contractions.fix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop=set(stopwords.words(\"english\"))\n",
    "    return \" \".join([word for word in str(text).split() if word not in stop])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_stopwords)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_stopwords)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern=re.compile(r\"https?://(www\\.)?(\\w+\\.)(\\w+)(/\\w*)?\")\n",
    "    return re.sub(pattern,\"\",text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_url)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_url)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def remove_space(text):\n",
    "    pattern=re.compile(r\" +\")\n",
    "    return re.sub(pattern,\" \",text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_space)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_space)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def remove_uni(text):\n",
    "    return text.encode(\"ascii\",\"ignore\").decode()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_uni)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_uni)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "lemma=WordNetLemmatizer()\n",
    "def lemmatization(text):\n",
    "    return \" \".join([lemma.lemmatize(word) for word in text.split()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(lemmatization)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(lemmatization)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].str.lower()\n",
    "test_df[\"text\"]=test_df[\"text\"].str.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    return re.sub('[%s]'%re.escape(string.punctuation),\"\",text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "train_df[\"text\"]=train_df[\"text\"].apply(remove_punctuation)\n",
    "test_df[\"text\"]=test_df[\"text\"].apply(remove_punctuation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset=Dataset.from_pandas(train_df[:7000])\n",
    "val_dataset=Dataset.from_pandas(train_df[7000:])\n",
    "test_dataset=Dataset.from_pandas(test_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfdb8dc22c194dfc89a7f1a98d350f9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13029df43be5474c936dc29b51cd6ec7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb25167ef9c746af9c49747d18004ba1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b50fa1c86bd14f50b7c9ccebe0c91f09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f53a2cdb0f0c483b9efd3b578618b1bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "checkpoint=\"bert-base-uncased\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(checkpoint)\n",
    "model=AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "def tokenize_function(example):\n",
    "  return tokenizer(example['text'], truncation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/7 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8af4e73861534089b7e7be9d77776be8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29a409bf9c5e419ca735025b8f167872"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75d29d762f144731ad734ea957e317e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset=train_dataset.map(tokenize_function,batched=True)\n",
    "test_dataset=test_dataset.map(tokenize_function,batched=True)\n",
    "val_dataset=val_dataset.map(tokenize_function,batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "['id',\n 'keyword',\n 'location',\n 'text',\n 'target',\n '__index_level_0__',\n 'input_ids',\n 'token_type_ids',\n 'attention_mask']"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.column_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.remove_columns(['id','keyword','location','text','__index_level_0__'])\n",
    "val_dataset=val_dataset.remove_columns(['id','keyword','location','text','__index_level_0__'])\n",
    "test_dataset=test_dataset.remove_columns(['id','location','keyword','text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 3263\n})"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.rename_column(\"target\",\"labels\")\n",
    "val_dataset=val_dataset.rename_column(\"target\",\"labels\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 7000\n})"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator=DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "train_dataset.set_format('torch')\n",
    "val_dataset.set_format('torch')\n",
    "test_dataset.set_format('torch')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data=DataLoader(train_dataset,shuffle=True,batch_size=64,collate_fn=data_collator)\n",
    "val_data=DataLoader(val_dataset,shuffle=True,batch_size=64,collate_fn=data_collator)\n",
    "test_data=DataLoader(test_dataset,shuffle=True,batch_size=8,collate_fn=data_collator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': torch.Size([64]), 'input_ids': torch.Size([64, 37]), 'token_type_ids': torch.Size([64, 37]), 'attention_mask': torch.Size([64, 37])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_data:\n",
    "  print({k:v.shape for k, v in batch.items()})\n",
    "  break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model=AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer=AdamW(model.parameters(),lr=5e-5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "epchoes=10\n",
    "num_step=epchoes*len(train_data)\n",
    "from transformers import get_scheduler\n",
    "lr_scheduler=get_scheduler('linear',num_warmup_steps=0,optimizer=optimizer,num_training_steps=num_step)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "from tqdm.auto import  tqdm\n",
    "import evaluate\n",
    "metric=evaluate.load(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48702740a5054636809c32253af4d3eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8190854870775348}\n",
      "{'accuracy': 0.8170974155069582}\n",
      "{'accuracy': 0.8151093439363817}\n",
      "{'accuracy': 0.8071570576540755}\n",
      "{'accuracy': 0.805168986083499}\n",
      "{'accuracy': 0.8250497017892644}\n",
      "{'accuracy': 0.7952286282306164}\n",
      "{'accuracy': 0.8151093439363817}\n",
      "{'accuracy': 0.8170974155069582}\n",
      "{'accuracy': 0.8210735586481114}\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "progress_bar=tqdm(range(num_step))\n",
    "for epoch in range(epchoes):\n",
    "    model.train()\n",
    "    loss=0\n",
    "    for batch in train_data:\n",
    "        batch={k:v.to(device) for k,v in batch.items()}\n",
    "        output=model(**batch)\n",
    "        loss=output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    model.eval()\n",
    "    for batch in val_data:\n",
    "        batch={k:v.to(device) for k,v in batch.items()}\n",
    "        output=model(**batch)\n",
    "        logits=output.logits\n",
    "        preds=torch.argmax(logits,dim=-1)\n",
    "        metric.add_batch(predictions=preds,references=batch['labels'])\n",
    "    print(metric.compute())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "preds=[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "for batch in test_data:\n",
    "    batch={k:v.to(device) for k,v in batch.items()}\n",
    "    output=model(**batch)\n",
    "    logits=output.logits\n",
    "    pred=torch.argmax(logits,dim=-1)\n",
    "    preds.append(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 1, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 1, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 1, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 1, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([1, 1, 0, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 1, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 1, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0'),\n tensor([1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 1, 0, 1, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 1, 0, 1, 1, 0, 1], device='cuda:0'),\n tensor([0, 1, 1, 1, 1, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 0, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 0, 1, 0, 1], device='cuda:0'),\n tensor([1, 0, 1, 1, 1, 1, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0'),\n tensor([1, 0, 0, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0'),\n tensor([0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0'),\n tensor([0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0'),\n tensor([0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0'),\n tensor([1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0'),\n tensor([1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0'),\n tensor([1, 1, 1, 0, 1, 0, 1, 1], device='cuda:0'),\n tensor([1, 0, 0, 0, 0, 1, 0], device='cuda:0')]"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "original_test_df=pd.read_csv('/data/linqinhong/kaggle/tweet_disaster/test.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "predictions=torch.cat([e for e in preds])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0')"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "original_test_df['target']=predictions.to('cpu').numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "         id keyword location  \\\n0         0     NaN      NaN   \n1         2     NaN      NaN   \n2         3     NaN      NaN   \n3         9     NaN      NaN   \n4        11     NaN      NaN   \n...     ...     ...      ...   \n3258  10861     NaN      NaN   \n3259  10865     NaN      NaN   \n3260  10868     NaN      NaN   \n3261  10874     NaN      NaN   \n3262  10875     NaN      NaN   \n\n                                                   text  target  \n0                    Just happened a terrible car crash       0  \n1     Heard about #earthquake is different cities, s...       0  \n2     there is a forest fire at spot pond, geese are...       0  \n3              Apocalypse lighting. #Spokane #wildfires       1  \n4         Typhoon Soudelor kills 28 in China and Taiwan       1  \n...                                                 ...     ...  \n3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...       0  \n3259  Storm in RI worse than last hurricane. My city...       0  \n3260  Green Line derailment in Chicago http://t.co/U...       0  \n3261  MEG issues Hazardous Weather Outlook (HWO) htt...       1  \n3262  #CityofCalgary has activated its Municipal Eme...       0  \n\n[3263 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Storm in RI worse than last hurricane. My city...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Green Line derailment in Chicago http://t.co/U...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#CityofCalgary has activated its Municipal Eme...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_test_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['text' 'keyword' 'location'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1357737/3342172202.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0moriginal_test_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'keyword'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'location'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0moriginal_test_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/data/linqinhong/kaggle/tweet_disaster/submission.csv'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/tweet/lib/python3.7/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/tweet/lib/python3.7/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mdrop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4911\u001B[0m             \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4912\u001B[0m             \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4913\u001B[0;31m             \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4914\u001B[0m         )\n\u001B[1;32m   4915\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/tweet/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36mdrop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4148\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;32min\u001B[0m \u001B[0maxes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4149\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4150\u001B[0;31m                 \u001B[0mobj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_drop_axis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4152\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/tweet/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m_drop_axis\u001B[0;34m(self, labels, axis, level, errors)\u001B[0m\n\u001B[1;32m   4183\u001B[0m                 \u001B[0mnew_axis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4184\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4185\u001B[0;31m                 \u001B[0mnew_axis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4186\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0maxis_name\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnew_axis\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4187\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/tweet/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mdrop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   6015\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6016\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0merrors\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m\"ignore\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6017\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{labels[mask]} not found in axis\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6018\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m~\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6019\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdelete\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['text' 'keyword' 'location'] not found in axis\""
     ]
    }
   ],
   "source": [
    "original_test_df.drop(['text','keyword','location'],axis=1,inplace=True)\n",
    "original_test_df.to_csv('/data/linqinhong/kaggle/tweet_disaster/submission.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "         id keyword location  \\\n0         1                    \n1         4                    \n2         5                    \n3         6                    \n4         7                    \n...     ...     ...      ...   \n7604  10863                    \n7605  10864                    \n7606  10866                    \n7608  10869                    \n7612  10873                    \n\n                                                   text  target  \n0       our deeds reason earthquake may allah forgive u       1  \n1                 forest fire near la ronge sask canada       1  \n2     all resident asked shelter place notified offi...       1  \n3     13000 people receive wildfires evacuation orde...       1  \n4     just got sent photo ruby alaska smoke wildfire...       1  \n...                                                 ...     ...  \n7604  worldnews fallen powerlines glink tram update ...       1  \n7605  flip side i walmart bomb everyone evacuate sta...       1  \n7606  suicide bomber kill 15 saudi security site mos...       1  \n7608  two giant crane holding bridge collapse nearby...       1  \n7612  the latest more homes razed northern californi...       1  \n\n[7503 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>our deeds reason earthquake may allah forgive u</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td></td>\n      <td></td>\n      <td>forest fire near la ronge sask canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td></td>\n      <td></td>\n      <td>all resident asked shelter place notified offi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td></td>\n      <td></td>\n      <td>13000 people receive wildfires evacuation orde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td></td>\n      <td></td>\n      <td>just got sent photo ruby alaska smoke wildfire...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7604</th>\n      <td>10863</td>\n      <td></td>\n      <td></td>\n      <td>worldnews fallen powerlines glink tram update ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7605</th>\n      <td>10864</td>\n      <td></td>\n      <td></td>\n      <td>flip side i walmart bomb everyone evacuate sta...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7606</th>\n      <td>10866</td>\n      <td></td>\n      <td></td>\n      <td>suicide bomber kill 15 saudi security site mos...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td></td>\n      <td></td>\n      <td>two giant crane holding bridge collapse nearby...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td></td>\n      <td></td>\n      <td>the latest more homes razed northern californi...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7503 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
